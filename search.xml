<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[grpc与graphql最佳实践]]></title>
    <url>%2F2019%2F10%2F24%2Fgrpc%E4%B8%8Egraphql%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[本文分为两部分，一部分翻译自effective-grpc，另一部分来自于集成grpc graphql实践。文章内容都是经过实践，请放心食用！ Effective grpcgrpc错误处理使用google.protobuf.Status消息将错误报告给客户端-gRPC库应针对您的语言对这种类型进行特殊区分（例如，grpc-go具有google.golang.org/grpc/status)。该消息可以包含任意子消息，因此服务器可以向所有客户端提供基本错误消息，并向可以处理这些错误的客户端提供结构化错误。 有关每个错误代码的含义的详细信息，请参考google/rpc/code.proto；有关如何编写错误消息的详细建议，请参考Google Cloud Error Model。 grpc-java中为io.grpc.Status 超时和截止时间服务器端处理程序应始终传播截止时间，客户几乎应该总是设定截止时间。优先选择截止时间而不是超时，因为在跨网络边界工作时，绝对时间戳的含义不如相对时间模糊。 根据你的实现库，有可能在service schema中定义默认超时，不要这样做-schema创建者无法预测哪种行为适合所有实现或用户。 访问地址始终遵循gRPC名称解析所使用的类似URL的语法，将gRPC地址表示并存储为完整字符串。诸如IP +端口元组之类的限制性格式会使想要在更大的框架或集成测试中运行您的代码的用户烦恼，这些测试可能对网络地址有自己的想法。 让地址设置在命令行标志或配置文件中，以便用户可以配置它们而不必修补二进制文件。即使您确实非常确定整个世界都希望在端口80上运行服务，也要这样做。 流gRPC支持单向和双向消息流，如果要传输的数据量可能很大，或者在完全接收到输入之前另一端可以有意义地处理数据，请使用流。例如，提供SHA256方法的服务可以在输入块到达时对其进行哈希处理，然后在客户端关闭请求流时将最终摘要发送回去。 与为每个块发送单独的RPC相比，流传输效率更高，但比所有块都位于重复字段中的单个RPC效率要低。流的开销可以通过使用批处理消息类型来最小化。 12345678910service Foo &#123; rpc MyStream(FooRequest) returns (stream MyStreamItem);&#125;message MyStreamItem &#123; repeated MyStreamValue values = 1;&#125;message MyStreamValue &#123; // ... fields for each logical value&#125; WARNING：在某些实现中（例如grpc-go），流句柄不是线程安全的，即使是客户端存根也不是。与来自多个线程的流句柄进行交互可能会导致不可预测的行为，包括静默消息损坏。 请求/响应类型在你的service中每个方法都应该有自己独有的请求和响应消息 123456service Foo &#123; rpc Bar(BarRequest) returns (BarResponse);&#125;message BarRequest &#123; ... &#125;message BarResponse &#123; ... &#125; 请不要在不同的方法中使用相同的消息，除非他们实际上是使用不同的API实现相同的方法(例如一元和流变种接收同样的响应)。即使这种情况，对于API也有可能有不同的部分，此时请新建另一个类型。 123456789service Foo &#123; rpc Bar(BarRequest) returns (BarResponse); rpc BarStream(BarRequest) returns (stream BarResponseStreamItem);&#125;message BarRequest &#123; ... &#125;message BarResponse &#123; ... &#125;message BarResponseStreamItem &#123; ... &#125; WARNING: 请不要使用google.protobuf.Empty作为请求和响应类型，他的API文档中的描述google/protobuf/empty.proto是一种反模式。如果你使用Empty， 那么将字段添加到请求/响应中将使所有客户端和服务器的API发生重大变化。 Protobuf包名使用软件包名称、项目名称、公司（如果适用）和语义版本控制主版本。确切的格式取决于个人喜好-流行的格式包括Java中使用的反向域名表示法，或核心gRPC类型使用的$COMPANY.$PROJECT om.mycompany.my_project.v1 com.mycompany.MyProject.v1 mycompany.my_project.v1尚未完全稳定的API版本应具有v1alpha，v2beta1或v3test之类的后缀。有关更详尽的指导，请参考Kubernetes API版本控制策略。 Protobuf软件包名称用于生成的代码中，因此请避免使用内置类型或关键字（例如return或void)等常用的名称。这对于生成C ++尤为重要，因为C ++（从protobuf 3.6起）没有FileOption来覆盖默认的namespace计算名称。 import path尝试从原始文件的位置构建，以使导入路径与程序包名称匹配：mycompany.my_project.v1中的类型应与import &quot;mycompany/my_project/v1/some_file.proto&quot;一起导入。 Protobuf工具链不是必需的，但是确实可以帮助我们记住输入的内容。 Next-Number 注释在大型protobuf消息中，弄清楚应该为新字段使用哪个字段编号可能会很烦人。为了简化将来的编辑者的工作，请在消息和枚举的末尾添加注释 12345message MyMessage &#123; // ... lots of fields here ... // NEXT: 42&#125; 枚举枚举作用域遵循旧式C/C ++规则，因此定义的名称不限于枚举名称： 1234567// symbol `FUN_LEVEL_HIGH&apos; is of type `FunLevel&apos;.enum FunLevel &#123; FUN_LEVEL_UNKNOWN = 0; FUN_LEVEL_LOW = 1; FUN_LEVEL_HIGH = 2; // NEXT: 3&#125; 枚举值不能重复，即使是在不同枚举类型中，你可能觉得这样很变态，但是事实就是这样的-_- 对于习惯于具有更现代范围规则的语言的用户而言，这可能很别扭。我喜欢用消息包装枚举： 123456789// symbol `FunLevel::HIGH` is of type `FunLevel::Enum`.message FunLevel &#123; enum Enum &#123; UNKNOWN = 0; LOW = 1; HIGH = 2; // NEXT: 3 &#125;&#125; 墓碑如果某个字段已被删除，则其字段编号不得再被将来的字段添加重用。通过添加带有逻辑标记的墓碑保留字来防止意外的字段号重用。我总是保留字段名称和编号: 12345678enum FunLevel &#123; // removed -- too much fun reserved &quot;FUN_LEVEL_EXCESSIVE&quot;; reserved 10;&#125;message MyMessage &#123; reserved &quot;crufty_old_field&quot;; reserved 20;&#125; 文档Protobuf没有用于API文档的内置生成器。在可用选项中，protoc-gen-doc似乎最成熟，请查看在protoc-gen-doc README中的语法和例子 参数验证Protobuf除了proto2（已在proto3中删除）所要求的之外，没有内置的验证机制。 envoyproxy的protoc-gen-validate工具是我所知道的最好的解决方案 可选的自定义类型在proto3中，删除了将标量字段（int32，字符串等）标记为可选的功能。标量字段现在始终存在，如果没有其他设置，将为默认的零值。当为其中&quot;&quot;和NULL是逻辑上不同的值的系统设计架构时，这可能令人沮丧。 官方解决方法是一组在Google/protobuf/wrappers.proto中定义的“包装器类型”，用于定义单值消息。你的架构可以使用google.protobuf.Int32Value而不是int32来获得可选性。 12345import &quot;google/protobuf/wrappers.proto&quot;;message MyMessage &#123; .google.protobuf.Int32Value some_field = 1;&#125; 另一种方法是将标量字段包装为oneof，而没有其他选择.并在生成的代码中添加辅助方法以检测是否设置了该字段,来迫使标量字段具有可选性。 12345message MyMessage &#123; oneof oneof_some_field &#123; int32 some_field = 1; &#125;&#125; graphql与grpc集成grapql是一种用于查询的api语言，跟protobuf一样同样的是使用schema描述，类型系统都是自己独有的。在与graphql和grpc集成过程最大问题就是类型问题。具体请查看graphql和grpc集成]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>grpc</tag>
        <tag>graphql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[org.hibernate.LazyInitializationException]]></title>
    <url>%2F2019%2F08%2F19%2Forg-hibernate-LazyInitializationException-could-not-initialize-proxy-xxxx-no%2F</url>
    <content type="text"><![CDATA[问题使用reflectasm的MethodAccess调用get方法出错，报错org.hibernate.LazyInitializationException: could not initialize proxy [com.bd.post.model.Post#2] - no Session 查错过程使用的orm框架是spring data jpa，LazyInitializationException第一时间想到hibernate和spring data jpa的懒加载机制。我理解的懒加载的概念是在真正使用数据的时候才去执行sql语句(配置外键关联)，查询对外建关联对象，但是我的model配置如下： 12345678910111213141516171819202122232425262728293031323334353637/** * @author &lt;a href=&quot;mailto:hilin2333@gmail.com&quot;&gt;created by silencecorner 2019/7/10 3:28 PM&lt;/a&gt; */@NoArgsConstructor@Entity@Data@EntityListeners(AuditingEntityListener.class)@ProtoClass(PostProto.Post.class)public class Post &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @ProtoField private Integer id; @ProtoField private String title; @ProtoField private String body; @ProtoField private Integer authorId; @CreatedDate @ProtoField(nullValue = ProtobufNullValueInspectorImpl.class,converter = LocalDateTimeConverterImpl.class) private LocalDateTime createdAt; @LastModifiedDate private LocalDateTime updatedAt; public Post(String title, String body) &#123; this.title = title; this.body = body; &#125; public Post(String title, String body, Integer authorId) &#123; this.title = title; this.body = body; this.authorId = authorId; &#125;&#125; 这里我并没有配置外键的关联对象呀！具体的错误信息里面又有no session，在orm框架里面都有session的概念对应数据库的session，在mybatis中是sqlsession,spring data jpa和hibernate中就叫session。检查代码发现使用了JpaRepository的getOne方法获取数据 1234567891011/*** Returns a reference to the entity with the given identifier. Depending on how the JPA persistence provider is* implemented this is very likely to always return an instance and throw an* &#123;@link javax.persistence.EntityNotFoundException&#125; on first access. Some of them will reject invalid identifiers* immediately.** @param id must not be &#123;@literal null&#125;.* @return a reference to the entity with the given identifier.* @see EntityManager#getReference(Class, Object) for details on when an exception is thrown.*/T getOne(ID id); 大概的意思是，只返回一个引用，信息看异常信息，what?找到调用的方法说明 123456789101112131415161718192021/** * Get an instance, whose state may be lazily fetched. * If the requested instance does not exist in the database, * the &lt;code&gt;EntityNotFoundException&lt;/code&gt; is thrown when the instance * state is first accessed. (The persistence provider runtime is * permitted to throw the &lt;code&gt;EntityNotFoundException&lt;/code&gt; when * &lt;code&gt;getReference&lt;/code&gt; is called.) * The application should not expect that the instance state will * be available upon detachment, unless it was accessed by the * application while the entity manager was open. * @param entityClass entity class * @param primaryKey primary key * @return the found entity instance * @throws IllegalArgumentException if the first argument does * not denote an entity type or the second argument is * not a valid type for that entity&apos;s primary key or * is null * @throws EntityNotFoundException if the entity state * cannot be accessed */public &lt;T&gt; T getReference(Class&lt;T&gt; entityClass, Object primaryKey); 这里终于说啦是懒加载，然后就是不希望这个对象变成游离态，除非entity manager打开。好吧！这里顺便回忆一下hibernate和jpa的对象状态，这些状态都是从martinfowler的工作单元/Unit of Work思想得来的。这些概念都是隶属于persistence coentext，翻译过来就是持久化上下文，既然隶属一个上下文那肯定是有关系的。其中 瞬时态/transient 新new的一个就是表对象，这个对象就是瞬时态 持久态/persistent 执行一下save方法，这个对象就变成持久态 游离态/detachment 这个保存过的对象修改属性之后就变成了游离态（ps:持久态修改属性都会变成游离态)。好了，上面有一句最关键的话就是unless it was accessed by the application while the entity manager was open。去找一下我们的EntityManager接口，它是实现了Session接口的。很自然的就想到了事务，持久化没有事务怎么能行（我当时写的时候还真没有加，哈哈！）。 代码源文件 123456789101112@Transactional@Overridepublic void updatePost(PostProto.UpdatePostRequest request, StreamObserver&lt;PostProto.Post&gt; responseObserver)&#123; check(request); // field_mask 填充字段 Configuration configuration = Configuration.builder().addIgnoredFields(new FieldsIgnore().add(Post.class, &quot;authorId&quot;, &quot;createdAt&quot;)).build(); Post post = Converter.create(configuration).toDomain(Post.class, request); Post newPost = postRepository.getOne(post.getId()); CopyUtils.copyProperties(post, newPost, true); responseObserver.onNext(modelToRpc(postRepository.save(newPost))); responseObserver.onCompleted();&#125; 那么在什么场景下去使用返回Optional的findById，什么时候使用返回懒加载对象的getOne呢？从含义上来讲，getOne表示数据一定存在，可以在udpate的时候使用，而findById 会立刻返回结果，可能存在也可能不存在。另外，getOne因为是返回的是一个引用，还没有具体执行，给一种异步的感觉，可以在响应式web程序中使用返回CompletableFuture等封装对象，当也得符合数据必须在数据库中存在这个条件。 解决懒加载需要将相应的东西保存到session，我们能控制就是加一个事务注解在方法上@Transactional声明这个方法没有执行完之前session不关闭。因为使用的spring boot，也可以加一个不推荐使用的配置： 1spring.jpa.properties.hibernate.enable_lazy_load_no_trans=true 搞定 总结jdbc的中sesion和数据库的sesion的是一个东西，sesion中保存当前会话变量事务声明！在hibernate和jpa中还有一个persistence coentext的概念：游离态、瞬时态、持久态，这些其实都是跟session密切相关的。 多看看学学还是有必要的，have a nice day ^_^!]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>issue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[graphql与grpc集成]]></title>
    <url>%2F2019%2F08%2F18%2Fgraphql-grpc-in-java-world-1%2F</url>
    <content type="text"><![CDATA[前言graphql和grpc的protobuf的schema都是一个描述性文件，只是双方的具体作用有差别而已。在Java中使用schema first的graphql-java-tools无疑是graphql在java语言的最佳入门实践，那么问题就来啦！protobuf和graphql各自都有自己的类型系统，graphql因为会序列化为json，那么就要遵从java bean的规范（序列化框架要求），protobuf使用的builder构造对象，没有默认的构造方法。 本文代码仓库地址:https://github.com/silencecorner/graphql-grpc-exmaple，如果了解graphql-java-kickstart的代码的话，可以直接查看源代码！ graphql-api nodejs实现的网关 graphql-gateway-java java实现的网关 post-api-java post服务端微服务程序 protos proto源文件 schema graphql文件目录 vue-apollo-sample 基于graphql规范的vue项目优化思路nodejs因为在去年实践过一次，没有深入思考，写起来总感觉有一点别扭！所以最开始我的想法是改用nodejs来写去掉类型检查，也写过一个在repo的graphql-api中converternodejs写起来挺简单的，但是java才是主要开发语言，所以又按照去年的那个套路实现了一次，按照converter的思路使用了protobuf-converter类库,优化了一下但是还是有一些不适。jackson序列化框架今天我就在想能不能jackson和protobuf之间做桥接一下，google搜索了果然已经有实现的类库，终于不用再写一遍java model啦！删除代码删除之前的inputs、types package，改用protobuf生成的代码，这里桥接要注入ProtobufModule，又想能不能直接使用返回ListenableFuture实例，通过查找资料可以实现。添加GraphqlToolConfiguration.java123456789101112131415@Configurationpublic class GraphqlToolConfiguration &#123; @Bean SchemaParserOptions options()&#123; ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json() .modules(new ProtobufModule(), new Jdk8Module(), new KotlinModule(), new JavaTimeModule()) .build(); return SchemaParserOptions.newOptions() .genericWrappers(SchemaParserOptions.GenericWrapper .withTransformer(ListenableFuture.class,0,ListenableFuturesExtra::toCompletableFuture, type -&gt; type)) .objectMapperProvider(fieldDefinition -&gt; objectMapper ) .useDefaultGenericWrappers(true) .build(); &#125;&#125; 这样我们就可以使用protobuf生成的class、grpc直接返回的ListenableFuture，字段对应protobuf的JsonName， schema.graphql123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869scalar DateTime# 作者type Author&#123; # unique id id: ID! # 名称 name: String&#125;# 添加作者参数input AddAuthorRequest&#123; # 名字 name: String!&#125;type Post &#123; # id id: ID # 标题 title: String # 内容 body: String # 创建时间 createdAt: DateTime # 文章作者 author: Author&#125;# 分页返回结果type Posts &#123; # 总数 count: Int # 当前页 page: Int # 条数 limit: Int # 结点 nodesList: [Post]&#125;# 添加文章参数input AddPostRequest &#123; # 标题 title: String # 内容 body: String&#125;# 分页参数input ListPostRequest&#123; # 第几页 page: Int! # 获取条数 limit: Int!&#125;type Query &#123; listPosts(request: ListPostRequest): Posts&#125;type Mutation &#123; addPost(request: AddPostRequest): Post # 新增作者 addAuthor(request: AddAuthorRequest!): Author&#125;schema &#123; query: Query mutation: Mutation&#125; Mutation.java12345678910111213141516@AllArgsConstructor@Componentpublic class Mutation implements GraphQLMutationResolver &#123; private final PostClient postClient; private final AuthorClient authorClient; public ListenableFuture&lt;PostProto.Post&gt; addPost(PostProto.AddPostRequest request)&#123; return postClient.addPost(request.toBuilder().setAuthorId(1).build()); &#125; public ListenableFuture&lt;AuthorProto.Author&gt; addAuthor(AuthorProto.AddAuthorRequest request)&#123; return authorClient.addAuthor(request); &#125;&#125; Query.java12345678@AllArgsConstructor@Componentpublic class Query implements GraphQLQueryResolver &#123; private final PostClient postClient; public ListenableFuture&lt;PostProto.Posts&gt; listPosts(PostProto.ListPostRequest request)&#123; return postClient.listPost(request); &#125;&#125; PostResolver.java1234567891011@Componentpublic class PostResolver implements GraphQLResolver&lt;PostProto.Post&gt; &#123; @Autowired private AuthorClient authorClient; public ListenableFuture&lt;AuthorProto.Author&gt; author(PostProto.Post post)&#123; return authorClient.getAuthor(post.getAuthorId()); &#125;&#125; PostsResolver.javaproto定义的是nodes字段，生成的java代码的get方法是getNodesList，此时对应的jackson的json字段就变成nodesList，我们的graphql中使用是nodes字段，按照graphql-java-tools的解析顺序 com.bd.gateway.resolvers.post.PostsResolver.nodes(sample.PostProto$Posts) com.bd.gateway.resolvers.post.PostsResolver.getNodes(sample.PostProto$Posts) com.bd.gateway.resolvers.post.PostsResolver.nodes sample.PostProto$Posts.nodes() sample.PostProto$Posts.getNodes() sample.PostProto$Posts.nodes 同样对repeated修饰的请求参数同样生效，通过添加graphql-java-tools List后缀匹配，解决repeated字段桥接转换失败的问题 PostClient.java1234567891011121314@Servicepublic class PostClient &#123; @GrpcClient(&quot;post-grpc-server&quot;) private PostServiceGrpc.PostServiceFutureStub postServiceFutureStub; public ListenableFuture&lt;PostProto.Post&gt; addPost(sample.PostProto.AddPostRequest request)&#123; return postServiceFutureStub.addPost(request); &#125; public ListenableFuture&lt;PostProto.Posts&gt; listPost(sample.PostProto.ListPostRequest request)&#123; return postServiceFutureStub.listPosts(request); &#125;&#125; AuthorClient.java1234567891011121314@Servicepublic class AuthorClient &#123; @GrpcClient("author-grpc-server") private AuthorServiceGrpc.AuthorServiceFutureStub authorServiceFutureStub; public ListenableFuture&lt;AuthorProto.Author&gt; addAuthor(AuthorProto.AddAuthorRequest request)&#123; return authorServiceFutureStub.addAuthor(request); &#125; public ListenableFuture&lt;AuthorProto.Author&gt; getAuthor(Integer id)&#123; return authorServiceFutureStub.getAuthor(AuthorProto.GetAuthorRequest.newBuilder().setId(id).build()); &#125;&#125; new featureproto3原生是不支持数据验证的，可能我们就要手写代码一个字段一个字段去做校验，项目中就会出现大量的丑陋到爆炸的代码。这里我找到一个protoc的validate plugin，目前支持 go gogo cc for c++ java 以目前情况来讲，不需要多语言调用，即使出现多语言调用的情况也可以，不影响正常调用，只是缺少验证而已，再不济也可以自己实现嘛！ 修改proto1234import &quot;validate/validate.proto&quot;;message AddAuthorRequest&#123; string name = 1 [(validate.rules).string = &#123;min_len: 5, max_len: 10&#125;];&#125; 修改build.gradle添加必要依赖12compile "io.envoyproxy.protoc-gen-validate:pgv-java-stub:$&#123;pgvVersion&#125;"compile "io.envoyproxy.protoc-gen-validate:pgv-java-grpc:$&#123;pgvVersion&#125;" 修改编译配置1234567891011121314151617181920212223protobuf &#123; // Configure the protoc executable protoc &#123; artifact = "com.google.protobuf:protoc:$&#123;protocVersion&#125;" &#125; plugins &#123; grpc &#123; artifact = "io.grpc:protoc-gen-grpc-java:$&#123;grpcVersion&#125;" &#125; javapgv &#123; artifact = "io.envoyproxy.protoc-gen-validate:protoc-gen-validate:$&#123;pgvVersion&#125;" &#125; &#125; generateProtoTasks &#123; all()*.plugins &#123; javapgv &#123; option "lang=java" &#125; grpc &#123;&#125; &#125; &#125;&#125; 添加客户端ValidatingClientInterceptor123456789101112@Configurationpublic class GlobalClientInterceptorConfiguration &#123; @Bean public GlobalClientInterceptorConfigurer globalInterceptorConfigurerAdapter() &#123; ValidatorIndex index = new ReflectiveValidatorIndex(); return registry -&gt; registry .addClientInterceptors(new LogGrpcInterceptor()) .addClientInterceptors(new ValidatingClientInterceptor(index)); &#125;&#125; 服务端添加ValidatingServerInterceptor12345678910@Configurationpublic class GlobalServerInterceptorConfiguration &#123; @Bean public GlobalServerInterceptorConfigurer globalInterceptorConfigurerAdapter() &#123; ValidatorIndex index = new ReflectiveValidatorIndex(); return registry -&gt; registry.addServerInterceptors(new ValidatingServerInterceptor(index)); &#125;&#125; 测试浏览器打开idea本地http://localhost:8888/playground浏览器打开docker本地http://localhost:8800/playground 123456mutation &#123; addAuthor(request: &#123; name: &quot;&quot; &#125;) &#123; id name &#125;&#125; 因为名字验证规则为长度5~10，这里name值为空，执行返回结果 1234567891011&#123; &quot;errors&quot;: [ &#123; &quot;message&quot;: &quot;INVALID_ARGUMENT: .sample.author.AddAuthorRequest.name: length must be 5 but got: 0 - Got \&quot;\&quot;&quot; &#125; ], &quot;extensions&quot;: &#123;&#125;, &quot;data&quot;: &#123; &quot;addAuthor&quot;: null &#125;&#125; 生效，啦啦啦！ 总结介绍graphql与gprc集成的一些问题，以及如何优化做到高效舒适的编写代码。 本文代码仓库地址:https://github.com/silencecorner/graphql-grpc-exmaple]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>grpc</tag>
        <tag>graphql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx部署静态vue项目时的注意事项]]></title>
    <url>%2F2019%2F08%2F17%2Fnginx%E9%83%A8%E7%BD%B2%E9%9D%99%E6%80%81vue%E9%A1%B9%E7%9B%AE%E6%97%B6%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[问题在使用webpack或者vuecli3作为脚手架开发vue项目时，使用内置的express编写测试代码都没有问题，运维拿到build生成的dist文件之后，需要通过这样方式访问http:/xxxx.com/content-path。如何部署才能保证前端页面资源正确加载呢？ 解决root部署假设content-path=post，运维同学要rename dist文件夹为post，上级文件目录C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample 1mv dist post 配置nginx.conf应该如下 1234location / &#123; root C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample; index index.html index.htm;&#125; 成功访问到http://localhost/post/ alias部署以root部署例子为前提,那么我们的配置文件nginx.conf应该如下 1234location /post &#123; alias C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample\dist; index index.html index.htm;&#125; 记得执行一下.\nginx.exe -s reload,这是访问我们的http://localhost/post/ 如图访问css资源http://localhost/css/app.e2707afb.css 404啦，我们怎样去给这个连接下加个post呢？以vuecli3为例,修改vue-config.js添加publicPath指定值为post 1234567891011console.log(`当前graphql网关访问地址:$&#123;process.env.VUE_APP_GRAPHQL_HTTP&#125;`)module.exports = &#123; publicPath: &apos;post&apos;, pluginOptions: &#123; graphqlMock: false, apolloEngine: false, &#125;, devServer: &#123; port: 8081, &#125;&#125; 此时重新打包再次访问就能正常访问啦！ 总结这里有两种部署方式，运维上来讲更倾向于第二种，前端可以配置使用process.env.XXX变来获取控制台变量，运维打包时想部署到任何路径都可以啦！当然使用root方式也是能达到效果，但是可能会给运维同学造成困扰，遇到这个问题的前端同学就不要说在本地我们用devServer跑都没问题的这种话啦! have a nice day ^_^]]></content>
      <categories>
        <category>前端</category>
        <category>运维</category>
      </categories>
      <tags>
        <tag>vue</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centeros docker安装及简单应用]]></title>
    <url>%2F2019%2F08%2F16%2Fcenteros-docker%E5%AE%89%E8%A3%85%E5%8F%8A%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[docker安裝 卸载12345678910sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 安裝默认安装stable版的，安装edge或者test版本的请自行查阅官方文档 12345678#安装配置管理工具sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce 安装指定版本12yum install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpmyum install -y docker-ce-17.03.0.ce-1.el7.centos.x86_64 docker 加速配置（centos7)123456789sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://id7d29lp.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.38:5000&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 配置非root用户使用docker123#bamboo 替换成你的用户名sudo setfacl -m user:bamboo:rw /var/run/docker.sock#还有一种方式就是在加入docker的group login12docker login#你的docker hub的用户名密码 用户名为参数登录 12docker login --username=gedit registry.cn-hangzhou.aliyuncs.com# 你的ali dockerhub的密码 docker machine1docker-machine create -d generic --generic-ip-address=192.168.1.67 --generic-ssh-user=administrator host67 swarm集群配置123sudo tee /etc/sysconfig/docker &lt;&lt;-&apos;EOF&apos;OPTIONS=&apos;-g /cutome-path/docker -H tcp://0.0.0.0:2375&apos;EOF 安装swarm1docker pull swarm 生成token1docker -H 192.168.1.38:8888 ps -a 设置管理节点在节点里面管理设置 1docker swarm init --advertise-addr 192.168.1.38 加入集群123docker swarm join \ --token SWMTKN-1-2hjlzufhptigxwvclhbn2b96rvn2ndl8wy8dqzn8otvjcibydp-7hppr5l9agyyp41wght5gpeo6 \ 192.168.1.41:2377 查看集群节点1docker node ls 执行命令1docker service create --name guoi-micro-shopie-shop -p 9039:9002 -p 8940:8902 --env JAVA_OPTS=&quot;-Xmx512m&quot; guoi/guoi-micro-shopie-shop --constraint &apos;node.hostname==istio-master&apos; 配置本地仓库原文链接 1docker run -d -p 5000:5000 -v /home/docker_registry:/var/lib/registry --restart=always --name registry registry:latest 123456# insecure-registries设置本地仓库位置cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://7xwv2psl.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.250:5000&quot;]&#125; 查看仓库位置 12curl -XGET http://192.168.1.250:5000/v2/_catalogcurl -XGET http://192.168.1.250:5000/v2/guoi/guoi-micro-shopie-catalog/tags/list jenkins jar运行123456789101112cd github/gedit_cloud_user_test/pid=`ps -ef | grep gedit-cloud-user-0.0.1-SNAPSHOT.jar | grep -v grep | awk &apos;&#123;print $2&#125;&apos;`if [ -n &quot;$pid&quot; ]then#!kill -9 强制终止 echo &quot;kill -9 的pid:&quot; $pid kill -9 $pidfilsgradle build -x test -x dockerBUILD_ID=DONTKILLME #jenkins环境变量nohup java -Dspring.profiles.active=test -jar -Xmx500m build/libs/gedit-cloud-user-0.0.1-SNAPSHOT.jar &gt;&gt;/root/log/gedit_user/user.log 2&gt;&amp;1&amp; docker mysql12345678910111213141516171819202122232425#dump datamysql -uroot gedit_store&gt;sqlbackup/gedit_store.docker.sqlmysql -uroot gedit_user&gt;sqlbackup/gedit_user.docker.sql#close mysqlsystemctl mysqld stop#install docker mysqldocker pull mysql #run instancedocker run -itd -p 3306:3306 mysql bash#login ttycontainer=$(docker ps|grep mysql|awk &apos;&#123;print $1&#125;&apos;)docker exec -it $container bash#create databasesmysql -urootcreate database gedit_store character set utf8mb4;create database gedit_user character set utf8mb4;exit#exit ttyexit#get mysql ipmysqlIp=$(docker ps|grep mysql|awk &apos;&#123;print $1&#125;&apos;|xargs docker inspect| grep IPAddress|sed -n &apos;2p&apos;|awk &apos;&#123;print $2&#125;&apos;|sed -e &apos;s/\&quot;//g&apos;|sed -e &apos;s/\,//g&apos;)echo &quot;mysql ip:$mysqlIp&quot;#backup data,need dump mysql datamysql -uroot -h$mysqlIp gedit_store&lt;sqlbackup/gedit_store.docker.sqlmysql -uroot -h$mysqlIp gedit_user&lt;sqlbackup/gedit_user.docker.sql 删除none镜像12#delete none imagesdocker rmi -f $(docker images | grep &apos;^&lt;none&gt;&apos; | awk &apos;&#123;print $3&#125;&apos;) jenkins docker12345678910111213141516171819BUILD_ID=DONTKILLMEgradle build -x test --refresh-dependenciessed &apos;s/-Dspring.profiles.active=test/-Dspring.profiles.active=test/g&apos; DockerfilecontainerId=$(docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $1&#125;&apos;)if [ $containerId ]then echo &quot;stop container id $containerId&quot; upContainerId=$(docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|grep &apos;Up&apos;|awk &apos;&#123;print $1&#125;&apos;) if [ $upContainerId ] then docker kill $upContainerId fi docker rm -f $containerId docker rmi -f $(docker images|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $3&#125;&apos;)figradle build docker -x test -x dockerPushdocker run --name gedit_storesearch -d -p 9091:9090 -p 9985:9985 --env JAVA_OPTS=&quot;-Xmx512m&quot; conanchen/gedit-cloud-storesearchsleep 30docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $1&#125;&apos;|xargs docker logs elasticsearch12docker pull docker.elastic.co/elasticsearch/elasticsearch:6.1.1docker run -d -it -p 19200:9200 -p 19300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx512m&quot; docker.elastic.co/elasticsearch/elasticsearch:6.1.1]]></content>
      <categories>
        <category>docker</category>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
</search>
