<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[graphql grpc in java world(1)]]></title>
    <url>%2F2019%2F08%2F18%2Fgraphql-grpc-in-java-world-1%2F</url>
    <content type="text"><![CDATA[前言graphql和grpc的protobuf的schema都是一个描述性文件，只是双方的具体作用有差别而已。在Java中使用schema first的graphql-java-tools无疑是graphql在java语言的最佳入门实践，那么问题就来啦！protobuf和graphql各自都有自己的类型系统，graphql因为会序列化为json，那么就要遵从java bean的规范（序列化框架要求），protobuf使用的builder构造对象，没有默认的构造方法。 优化思路nodejs因为在去年实践过一次，没有深入思考，写起来总感觉有一点别扭！所以最开始我的想法是改用nodejs来写去掉类型检查，也写过一个在repo的graphql-api中 converternodejs写起来挺简单的，但是java才是主要开发语言，所以又按照去年的那个套路实现了一次，按照converter的思路使用了protobuf-converter类库,优化了一下但是还是有一些不适。 jackson序列化框架今天我就在想能不能jackson和protobuf之间做桥接一下，google搜索了果然已经有实现的类库，终于不用再写一遍java model啦！ 删除代码删除之前的inputs、types package，改用protobuf生成的代码，这里桥接要注入ProtobufModule，又想能不能直接使用返回ListenableFuture实例，通过查找资料可以实现. 添加GraphqlToolConfiguration.java123456789101112131415@Configurationpublic class GraphqlToolConfiguration &#123; @Bean SchemaParserOptions options()&#123; ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json() .modules(new ProtobufModule(), new Jdk8Module(), new KotlinModule(), new JavaTimeModule()) .build(); return SchemaParserOptions.newOptions() .genericWrappers(SchemaParserOptions.GenericWrapper .withTransformer(ListenableFuture.class,0,ListenableFuturesExtra::toCompletableFuture, type -&gt; type)) .objectMapperProvider(fieldDefinition -&gt; objectMapper ) .useDefaultGenericWrappers(true) .build(); &#125;&#125; 这样我们就可以使用protobuf生成的class、grpc直接返回的ListenableFuture，字段对应protobuf的JsonName， schema.graphql123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869scalar DateTime# 作者type Author&#123; # unique id id: ID! # 名称 name: String&#125;# 添加作者参数input AddAuthorRequest&#123; # 名字 name: String!&#125;type Post &#123; # id id: ID # 标题 title: String # 内容 body: String # 创建时间 createdAt: DateTime # 文章作者 author: Author&#125;# 分页返回结果type Posts &#123; # 总数 count: Int # 当前页 page: Int # 条数 limit: Int # 结点 nodesList: [Post]&#125;# 添加文章参数input AddPostRequest &#123; # 标题 title: String # 内容 body: String&#125;# 分页参数input ListPostRequest&#123; # 第几页 page: Int! # 获取条数 limit: Int!&#125;type Query &#123; listPosts(request: ListPostRequest): Posts&#125;type Mutation &#123; addPost(request: AddPostRequest): Post # 新增作者 addAuthor(request: AddAuthorRequest!): Author&#125;schema &#123; query: Query mutation: Mutation&#125; Mutation.java12345678910111213141516@AllArgsConstructor@Componentpublic class Mutation implements GraphQLMutationResolver &#123; private final PostClient postClient; private final AuthorClient authorClient; public ListenableFuture&lt;PostProto.Post&gt; addPost(PostProto.AddPostRequest request)&#123; return postClient.addPost(request.toBuilder().setAuthorId(1).build()); &#125; public ListenableFuture&lt;AuthorProto.Author&gt; addAuthor(AuthorProto.AddAuthorRequest request)&#123; return authorClient.addAuthor(request); &#125;&#125; Query.java12345678@AllArgsConstructor@Componentpublic class Query implements GraphQLQueryResolver &#123; private final PostClient postClient; public ListenableFuture&lt;PostProto.Posts&gt; listPosts(PostProto.ListPostRequest request)&#123; return postClient.listPost(request); &#125;&#125; PostResolver.java1234567891011@Componentpublic class PostResolver implements GraphQLResolver&lt;PostProto.Post&gt; &#123; @Autowired private AuthorClient authorClient; public ListenableFuture&lt;AuthorProto.Author&gt; author(PostProto.Post post)&#123; return authorClient.getAuthor(post.getAuthorId()); &#125;&#125; PostClient.java1234567891011121314@Servicepublic class PostClient &#123; @GrpcClient(&quot;post-grpc-server&quot;) private PostServiceGrpc.PostServiceFutureStub postServiceFutureStub; public ListenableFuture&lt;PostProto.Post&gt; addPost(sample.PostProto.AddPostRequest request)&#123; return postServiceFutureStub.addPost(request); &#125; public ListenableFuture&lt;PostProto.Posts&gt; listPost(sample.PostProto.ListPostRequest request)&#123; return postServiceFutureStub.listPosts(request); &#125;&#125; AuthorClient.java1234567891011121314@Servicepublic class AuthorClient &#123; @GrpcClient("author-grpc-server") private AuthorServiceGrpc.AuthorServiceFutureStub authorServiceFutureStub; public ListenableFuture&lt;AuthorProto.Author&gt; addAuthor(AuthorProto.AddAuthorRequest request)&#123; return authorServiceFutureStub.addAuthor(request); &#125; public ListenableFuture&lt;AuthorProto.Author&gt; getAuthor(Integer id)&#123; return authorServiceFutureStub.getAuthor(AuthorProto.GetAuthorRequest.newBuilder().setId(id).build()); &#125;&#125; new featureproto3原生是不支持数据验证的，可能我们就要手写代码一个字段一个字段去做校验，项目中就会出现大量的丑陋到爆炸的代码。这里我找到一个protoc的validate plugin，目前支持 go gogo cc for c++ java 以目前情况来讲，不需要多语言调用，即使出现多语言调用的情况也可以，不影响正常调用，只是缺少验证而已，再不济也可以自己实现嘛！ 修改proto1234import &quot;validate/validate.proto&quot;;message AddAuthorRequest&#123; string name = 1 [(validate.rules).string = &#123;min_len: 5, max_len: 10&#125;];&#125; 修改build.gradle添加必要依赖12compile "io.envoyproxy.protoc-gen-validate:pgv-java-stub:$&#123;pgvVersion&#125;"compile "io.envoyproxy.protoc-gen-validate:pgv-java-grpc:$&#123;pgvVersion&#125;" 修改编译配置1234567891011121314151617181920212223protobuf &#123; // Configure the protoc executable protoc &#123; artifact = "com.google.protobuf:protoc:$&#123;protocVersion&#125;" &#125; plugins &#123; grpc &#123; artifact = "io.grpc:protoc-gen-grpc-java:$&#123;grpcVersion&#125;" &#125; javapgv &#123; artifact = "io.envoyproxy.protoc-gen-validate:protoc-gen-validate:$&#123;pgvVersion&#125;" &#125; &#125; generateProtoTasks &#123; all()*.plugins &#123; javapgv &#123; option "lang=java" &#125; grpc &#123;&#125; &#125; &#125;&#125; 添加客户端ValidatingClientInterceptor123456789101112@Configurationpublic class GlobalClientInterceptorConfiguration &#123; @Bean public GlobalClientInterceptorConfigurer globalInterceptorConfigurerAdapter() &#123; ValidatorIndex index = new ReflectiveValidatorIndex(); return registry -&gt; registry .addClientInterceptors(new LogGrpcInterceptor()) .addClientInterceptors(new ValidatingClientInterceptor(index)); &#125;&#125; 服务端添加ValidatingServerInterceptor12345678910@Configurationpublic class GlobalClientInterceptorConfiguration &#123; @Bean public GlobalServerInterceptorConfigurer globalInterceptorConfigurerAdapter() &#123; ValidatorIndex index = new ReflectiveValidatorIndex(); return registry -&gt; registry.addServerInterceptors(new ValidatingServerInterceptor(index)); &#125;&#125; 测试浏览器打开idea本地http://localhost:8888/playground浏览器打开docker本地http://localhost:8000/playground 123456mutation &#123; addAuthor(request: &#123; name: &quot;&quot; &#125;) &#123; id name &#125;&#125; 因为名字验证规则为长度5~10，这里name值为空，执行返回结果 1234567891011&#123; &quot;errors&quot;: [ &#123; &quot;message&quot;: &quot;INVALID_ARGUMENT: .sample.author.AddAuthorRequest.name: length must be 5 but got: 0 - Got \&quot;\&quot;&quot; &#125; ], &quot;extensions&quot;: &#123;&#125;, &quot;data&quot;: &#123; &quot;addAuthor&quot;: null &#125;&#125; 生效，啦啦啦！ 总结介绍graphql、gprc in java world的一些问题，一些intergration的思路，新特性参数验证，下一篇介绍使用graphql结合field mask做单项更新！]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>graphql</tag>
        <tag>grpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx部署静态vue项目时的注意事项]]></title>
    <url>%2F2019%2F08%2F17%2Fnginx%E9%83%A8%E7%BD%B2%E9%9D%99%E6%80%81vue%E9%A1%B9%E7%9B%AE%E6%97%B6%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[问题在使用webpack或者vuecli3作为脚手架开发vue项目时，使用内置的express编写测试代码都没有问题，运维拿到build生成的dist文件之后，需要通过这样方式访问http:/xxxx.com/content-path。如何部署才能保证前端页面资源正确加载呢？ 解决root部署假设content-path=post，运维同学要rename dist文件夹为post，上级文件目录C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample 1mv dist post 配置nginx.conf应该如下 1234location / &#123; root C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample; index index.html index.htm;&#125; 成功访问到http://localhost/post/ alias部署以root部署例子为前提,那么我们的配置文件nginx.conf应该如下 1234location /post &#123; alias C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample\dist; index index.html index.htm;&#125; 记得执行一下.\nginx.exe -s reload,这是访问我们的http://localhost/post/ 如图访问css资源http://localhost/css/app.e2707afb.css 404啦，我们怎样去给这个连接下加个post呢？以vuecli3为例,修改vue-config.js添加publicPath指定值为post 1234567891011console.log(`当前graphql网关访问地址:$&#123;process.env.VUE_APP_GRAPHQL_HTTP&#125;`)module.exports = &#123; publicPath: &apos;post&apos;, pluginOptions: &#123; graphqlMock: false, apolloEngine: false, &#125;, devServer: &#123; port: 8081, &#125;&#125; 此时重新打包再次访问就能正常访问啦！ 总结这里有两种部署方式，运维上来讲更倾向于第二种，前端可以配置使用process.env.XXX变来获取控制台变量，运维打包时想部署到任何路径都可以啦！当然使用root方式也是能达到效果，但是可能会给运维同学造成困扰，遇到这个问题的前端同学就不要说在本地我们用devServer跑都没问题的这种话啦! have a nice day ^_^]]></content>
      <categories>
        <category>前端</category>
        <category>运维</category>
      </categories>
      <tags>
        <tag>vue</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centeros docker安装及简单应用]]></title>
    <url>%2F2019%2F08%2F16%2Fcenteros-docker%E5%AE%89%E8%A3%85%E5%8F%8A%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[docker安裝卸载12345678910sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 安裝默认安装stable版的，安装edge或者test版本的请自行查阅官方文档 12345678#安装配置管理工具sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce 安装指定版本12yum install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpmyum install -y docker-ce-17.03.0.ce-1.el7.centos.x86_64 docker 加速配置（centos7)123456789sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://id7d29lp.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.38:5000&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 配置非root用户使用docker123#bamboo 替换成你的用户名sudo setfacl -m user:bamboo:rw /var/run/docker.sock#还有一种方式就是在加入docker的group login12docker login#你的docker hub的用户名密码 用户名为参数登录 12docker login --username=gedit registry.cn-hangzhou.aliyuncs.com# 你的ali dockerhub的密码 docker machine1docker-machine create -d generic --generic-ip-address=192.168.1.67 --generic-ssh-user=administrator host67 swarm集群配置123sudo tee /etc/sysconfig/docker &lt;&lt;-&apos;EOF&apos;OPTIONS=&apos;-g /cutome-path/docker -H tcp://0.0.0.0:2375&apos;EOF 安装swarm1docker pull swarm 生成token1docker -H 192.168.1.38:8888 ps -a 设置管理节点在节点里面管理设置 1docker swarm init --advertise-addr 192.168.1.38 加入集群123docker swarm join \ --token SWMTKN-1-2hjlzufhptigxwvclhbn2b96rvn2ndl8wy8dqzn8otvjcibydp-7hppr5l9agyyp41wght5gpeo6 \ 192.168.1.41:2377 查看集群节点1docker node ls 执行命令1docker service create --name guoi-micro-shopie-shop -p 9039:9002 -p 8940:8902 --env JAVA_OPTS=&quot;-Xmx512m&quot; guoi/guoi-micro-shopie-shop --constraint &apos;node.hostname==istio-master&apos; 配置本地仓库原文链接 1docker run -d -p 5000:5000 -v /home/docker_registry:/var/lib/registry --restart=always --name registry registry:latest 123456# insecure-registries设置本地仓库位置cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://7xwv2psl.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.250:5000&quot;]&#125; 查看仓库位置 12curl -XGET http://192.168.1.250:5000/v2/_catalogcurl -XGET http://192.168.1.250:5000/v2/guoi/guoi-micro-shopie-catalog/tags/list jenkins jar运行123456789101112cd github/gedit_cloud_user_test/pid=`ps -ef | grep gedit-cloud-user-0.0.1-SNAPSHOT.jar | grep -v grep | awk &apos;&#123;print $2&#125;&apos;`if [ -n &quot;$pid&quot; ]then#!kill -9 强制终止 echo &quot;kill -9 的pid:&quot; $pid kill -9 $pidfilsgradle build -x test -x dockerBUILD_ID=DONTKILLME #jenkins环境变量nohup java -Dspring.profiles.active=test -jar -Xmx500m build/libs/gedit-cloud-user-0.0.1-SNAPSHOT.jar &gt;&gt;/root/log/gedit_user/user.log 2&gt;&amp;1&amp; docker mysql12345678910111213141516171819202122232425#dump datamysql -uroot gedit_store&gt;sqlbackup/gedit_store.docker.sqlmysql -uroot gedit_user&gt;sqlbackup/gedit_user.docker.sql#close mysqlsystemctl mysqld stop#install docker mysqldocker pull mysql #run instancedocker run -itd -p 3306:3306 mysql bash#login ttycontainer=$(docker ps|grep mysql|awk &apos;&#123;print $1&#125;&apos;)docker exec -it $container bash#create databasesmysql -urootcreate database gedit_store character set utf8mb4;create database gedit_user character set utf8mb4;exit#exit ttyexit#get mysql ipmysqlIp=$(docker ps|grep mysql|awk &apos;&#123;print $1&#125;&apos;|xargs docker inspect| grep IPAddress|sed -n &apos;2p&apos;|awk &apos;&#123;print $2&#125;&apos;|sed -e &apos;s/\&quot;//g&apos;|sed -e &apos;s/\,//g&apos;)echo &quot;mysql ip:$mysqlIp&quot;#backup data,need dump mysql datamysql -uroot -h$mysqlIp gedit_store&lt;sqlbackup/gedit_store.docker.sqlmysql -uroot -h$mysqlIp gedit_user&lt;sqlbackup/gedit_user.docker.sql 删除none镜像12#delete none imagesdocker rmi -f $(docker images | grep &apos;^&lt;none&gt;&apos; | awk &apos;&#123;print $3&#125;&apos;) jenkins docker12345678910111213141516171819BUILD_ID=DONTKILLMEgradle build -x test --refresh-dependenciessed &apos;s/-Dspring.profiles.active=test/-Dspring.profiles.active=test/g&apos; DockerfilecontainerId=$(docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $1&#125;&apos;)if [ $containerId ]then echo &quot;stop container id $containerId&quot; upContainerId=$(docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|grep &apos;Up&apos;|awk &apos;&#123;print $1&#125;&apos;) if [ $upContainerId ] then docker kill $upContainerId fi docker rm -f $containerId docker rmi -f $(docker images|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $3&#125;&apos;)figradle build docker -x test -x dockerPushdocker run --name gedit_storesearch -d -p 9091:9090 -p 9985:9985 --env JAVA_OPTS=&quot;-Xmx512m&quot; conanchen/gedit-cloud-storesearchsleep 30docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $1&#125;&apos;|xargs docker logs elasticsearch12docker pull docker.elastic.co/elasticsearch/elasticsearch:6.1.1docker run -d -it -p 19200:9200 -p 19300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx512m&quot; docker.elastic.co/elasticsearch/elasticsearch:6.1.1]]></content>
      <categories>
        <category>docker</category>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
</search>
