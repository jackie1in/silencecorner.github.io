<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[org.hibernate.LazyInitializationException: could not initialize proxy xxxx no Session]]></title>
    <url>%2F2019%2F08%2F19%2Forg-hibernate-LazyInitializationException-could-not-initialize-proxy-xxxx-no%2F</url>
    <content type="text"><![CDATA[问题使用reflectasm MethodAccess调用get方法出错，报错org.hibernate.LazyInitializationException: could not initialize proxy [com.bd.post.model.Post#2] - no Session 查错过程使用的orm框架是spring data jpa，LazyInitializationException第一时间想到hibernate和spring data jpa的懒加载机制。我理解的懒加载的概念是在真正使用数据的时候才去执行sql语句(配置外键关联)，查询对外建关联对象，但是我的model配置如下： 12345678910111213141516171819202122232425262728293031323334353637/** * @author &lt;a href=&quot;mailto:hilin2333@gmail.com&quot;&gt;created by silencecorner 2019/7/10 3:28 PM&lt;/a&gt; */@NoArgsConstructor@Entity@Data@EntityListeners(AuditingEntityListener.class)@ProtoClass(PostProto.Post.class)public class Post &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @ProtoField private Integer id; @ProtoField private String title; @ProtoField private String body; @ProtoField private Integer authorId; @CreatedDate @ProtoField(nullValue = ProtobufNullValueInspectorImpl.class,converter = LocalDateTimeConverterImpl.class) private LocalDateTime createdAt; @LastModifiedDate private LocalDateTime updatedAt; public Post(String title, String body) &#123; this.title = title; this.body = body; &#125; public Post(String title, String body, Integer authorId) &#123; this.title = title; this.body = body; this.authorId = authorId; &#125;&#125; 这里我并没有配置外键的关联对象呀！具体的错误信息里面又有no session，在orm框架里面都有session的概念对应数据库的session，在mybatis中是sqlsession,spring data jpa和hibernate中就叫session。检查代码发现使用了JpaRepository的getOne方法获取数据 1234567891011/*** Returns a reference to the entity with the given identifier. Depending on how the JPA persistence provider is* implemented this is very likely to always return an instance and throw an* &#123;@link javax.persistence.EntityNotFoundException&#125; on first access. Some of them will reject invalid identifiers* immediately.** @param id must not be &#123;@literal null&#125;.* @return a reference to the entity with the given identifier.* @see EntityManager#getReference(Class, Object) for details on when an exception is thrown.*/T getOne(ID id); 大概的意思是，只返回一个引用，信息看异常信息，what?找到调用的方法说明 123456789101112131415161718192021/** * Get an instance, whose state may be lazily fetched. * If the requested instance does not exist in the database, * the &lt;code&gt;EntityNotFoundException&lt;/code&gt; is thrown when the instance * state is first accessed. (The persistence provider runtime is * permitted to throw the &lt;code&gt;EntityNotFoundException&lt;/code&gt; when * &lt;code&gt;getReference&lt;/code&gt; is called.) * The application should not expect that the instance state will * be available upon detachment, unless it was accessed by the * application while the entity manager was open. * @param entityClass entity class * @param primaryKey primary key * @return the found entity instance * @throws IllegalArgumentException if the first argument does * not denote an entity type or the second argument is * not a valid type for that entity&apos;s primary key or * is null * @throws EntityNotFoundException if the entity state * cannot be accessed */public &lt;T&gt; T getReference(Class&lt;T&gt; entityClass, Object primaryKey); 这里终于说啦是懒加载，然后就是不希望这个对象变成游离态，除非entity manager打开。好吧！这里顺便回忆一下hibernate和jpa的对象状态，这些状态都是从martinfowler的工作单元/Unit of Work思想得来的。这些概念都是隶属于persistence coentext，翻译过来就是持久化上下文，既然隶属一个上下文那肯定是有关系的。其中 瞬时态/transient 新new的一个就是表对象，这个对象就是瞬时态 持久态/persistent 执行一下save方法，这个就是游离态 游离态/detachment 这个保存过的对象修改属性之后就变成了游离态（ps:持久态修改属性都会变成游离态)好了，上面有一句最关键的话就是unless it was accessed by the application while the entity manager was open。去找一下我们的EntityManager接口，它是实现了Session接口的。很自然的就想到了事务，持久化没有事务怎么能行（我当时写的时候还真没有加，哈哈！） 那么在什么场景下去使用返回Optional的findById，什么时候使用返回懒加载对象的getOne呢？从含义上来讲，getOne表示数据一定存在，可以在udpate的时候使用，而findById 会立刻返回结果，可能存在也可能不存在。另外，getOne因为是返回的是一个引用，还没有具体执行，给一种异步的感觉，可以在响应式web程序中使用返回CompletableFuture等封装对象，当也得符合数据必须在数据库中存在这个条件。 解决懒加载需要将相应的东西保存到session，我们能控制就是加一个事务注解在方法上@Transactional声明这个方法没有执行完之前session不关闭。因为使用的spring boot，加一个配置： 1spring.jpa.properties.hibernate.enable_lazy_load_no_trans=true 搞定 总结jdbc的中sesion和数据库的sesion的是一个东西，sesion中保存当前会话变量事务声明！在hibernate和jpa中还有一个persistence coentext的概念：游离态、瞬时态、持久态，这些其实都是跟session密切相关的。 多看看学学还是有必要的，have a nice day ^_^!]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>issue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[graphql grpc in java world(1)]]></title>
    <url>%2F2019%2F08%2F18%2Fgraphql-grpc-in-java-world-1%2F</url>
    <content type="text"><![CDATA[前言graphql和grpc的protobuf的schema都是一个描述性文件，只是双方的具体作用有差别而已。在Java中使用schema first的graphql-java-tools无疑是graphql在java语言的最佳入门实践，那么问题就来啦！protobuf和graphql各自都有自己的类型系统，graphql因为会序列化为json，那么就要遵从java bean的规范（序列化框架要求），protobuf使用的builder构造对象，没有默认的构造方法。本文代码仓库地址:https://github.com/silencecorner/graphql-grpc-exmaple/tree/0.2.0，如果了解graphql-java-kickstart的代码的话，可以直接查看源代码！ graphql-api nodejs实现的网关 graphql-gateway-java java实现的网关 post-api-java post服务端微服务程序 protos proto源文件 schema graphql文件目录 vue-apollo-sample 基于graphql规范的vue项目优化思路nodejs因为在去年实践过一次，没有深入思考，写起来总感觉有一点别扭！所以最开始我的想法是改用nodejs来写去掉类型检查，也写过一个在repo的graphql-api中converternodejs写起来挺简单的，但是java才是主要开发语言，所以又按照去年的那个套路实现了一次，按照converter的思路使用了protobuf-converter类库,优化了一下但是还是有一些不适。jackson序列化框架今天我就在想能不能jackson和protobuf之间做桥接一下，google搜索了果然已经有实现的类库，终于不用再写一遍java model啦！删除代码删除之前的inputs、types package，改用protobuf生成的代码，这里桥接要注入ProtobufModule，又想能不能直接使用返回ListenableFuture实例，通过查找资料可以实现。 添加GraphqlToolConfiguration.java123456789101112131415@Configurationpublic class GraphqlToolConfiguration &#123; @Bean SchemaParserOptions options()&#123; ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json() .modules(new ProtobufModule(), new Jdk8Module(), new KotlinModule(), new JavaTimeModule()) .build(); return SchemaParserOptions.newOptions() .genericWrappers(SchemaParserOptions.GenericWrapper .withTransformer(ListenableFuture.class,0,ListenableFuturesExtra::toCompletableFuture, type -&gt; type)) .objectMapperProvider(fieldDefinition -&gt; objectMapper ) .useDefaultGenericWrappers(true) .build(); &#125;&#125; 这样我们就可以使用protobuf生成的class、grpc直接返回的ListenableFuture，字段对应protobuf的JsonName， schema.graphql123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869scalar DateTime# 作者type Author&#123; # unique id id: ID! # 名称 name: String&#125;# 添加作者参数input AddAuthorRequest&#123; # 名字 name: String!&#125;type Post &#123; # id id: ID # 标题 title: String # 内容 body: String # 创建时间 createdAt: DateTime # 文章作者 author: Author&#125;# 分页返回结果type Posts &#123; # 总数 count: Int # 当前页 page: Int # 条数 limit: Int # 结点 nodesList: [Post]&#125;# 添加文章参数input AddPostRequest &#123; # 标题 title: String # 内容 body: String&#125;# 分页参数input ListPostRequest&#123; # 第几页 page: Int! # 获取条数 limit: Int!&#125;type Query &#123; listPosts(request: ListPostRequest): Posts&#125;type Mutation &#123; addPost(request: AddPostRequest): Post # 新增作者 addAuthor(request: AddAuthorRequest!): Author&#125;schema &#123; query: Query mutation: Mutation&#125; Mutation.java12345678910111213141516@AllArgsConstructor@Componentpublic class Mutation implements GraphQLMutationResolver &#123; private final PostClient postClient; private final AuthorClient authorClient; public ListenableFuture&lt;PostProto.Post&gt; addPost(PostProto.AddPostRequest request)&#123; return postClient.addPost(request.toBuilder().setAuthorId(1).build()); &#125; public ListenableFuture&lt;AuthorProto.Author&gt; addAuthor(AuthorProto.AddAuthorRequest request)&#123; return authorClient.addAuthor(request); &#125;&#125; Query.java12345678@AllArgsConstructor@Componentpublic class Query implements GraphQLQueryResolver &#123; private final PostClient postClient; public ListenableFuture&lt;PostProto.Posts&gt; listPosts(PostProto.ListPostRequest request)&#123; return postClient.listPost(request); &#125;&#125; PostResolver.java1234567891011@Componentpublic class PostResolver implements GraphQLResolver&lt;PostProto.Post&gt; &#123; @Autowired private AuthorClient authorClient; public ListenableFuture&lt;AuthorProto.Author&gt; author(PostProto.Post post)&#123; return authorClient.getAuthor(post.getAuthorId()); &#125;&#125; PostsResolver.javaproto定义的是nodes字段，生成的java代码的get方法是getNodesList，此时对应的jackson的json字段就变成nodesList，我们的graphql中使用是nodes字段，按照graphql-tools的解析顺序 com.bd.gateway.resolvers.post.PostsResolver.nodes(sample.PostProto$Posts) com.bd.gateway.resolvers.post.PostsResolver.getNodes(sample.PostProto$Posts) com.bd.gateway.resolvers.post.PostsResolver.nodes sample.PostProto$Posts.nodes() sample.PostProto$Posts.getNodes() sample.PostProto$Posts.nodes 添加如下代码就可以解决字段不一样的问题啦！ 1234567@Componentpublic class PostsResolver implements GraphQLResolver&lt;PostProto.Posts&gt; &#123; public List&lt;PostProto.Post&gt; nodes(PostProto.Posts posts)&#123; return posts.getNodesList(); &#125;&#125; PostClient.java1234567891011121314@Servicepublic class PostClient &#123; @GrpcClient(&quot;post-grpc-server&quot;) private PostServiceGrpc.PostServiceFutureStub postServiceFutureStub; public ListenableFuture&lt;PostProto.Post&gt; addPost(sample.PostProto.AddPostRequest request)&#123; return postServiceFutureStub.addPost(request); &#125; public ListenableFuture&lt;PostProto.Posts&gt; listPost(sample.PostProto.ListPostRequest request)&#123; return postServiceFutureStub.listPosts(request); &#125;&#125; AuthorClient.java1234567891011121314@Servicepublic class AuthorClient &#123; @GrpcClient("author-grpc-server") private AuthorServiceGrpc.AuthorServiceFutureStub authorServiceFutureStub; public ListenableFuture&lt;AuthorProto.Author&gt; addAuthor(AuthorProto.AddAuthorRequest request)&#123; return authorServiceFutureStub.addAuthor(request); &#125; public ListenableFuture&lt;AuthorProto.Author&gt; getAuthor(Integer id)&#123; return authorServiceFutureStub.getAuthor(AuthorProto.GetAuthorRequest.newBuilder().setId(id).build()); &#125;&#125; new featureproto3原生是不支持数据验证的，可能我们就要手写代码一个字段一个字段去做校验，项目中就会出现大量的丑陋到爆炸的代码。这里我找到一个protoc的validate plugin，目前支持 go gogo cc for c++ java 以目前情况来讲，不需要多语言调用，即使出现多语言调用的情况也可以，不影响正常调用，只是缺少验证而已，再不济也可以自己实现嘛！ 修改proto1234import &quot;validate/validate.proto&quot;;message AddAuthorRequest&#123; string name = 1 [(validate.rules).string = &#123;min_len: 5, max_len: 10&#125;];&#125; 修改build.gradle添加必要依赖12compile "io.envoyproxy.protoc-gen-validate:pgv-java-stub:$&#123;pgvVersion&#125;"compile "io.envoyproxy.protoc-gen-validate:pgv-java-grpc:$&#123;pgvVersion&#125;" 修改编译配置1234567891011121314151617181920212223protobuf &#123; // Configure the protoc executable protoc &#123; artifact = "com.google.protobuf:protoc:$&#123;protocVersion&#125;" &#125; plugins &#123; grpc &#123; artifact = "io.grpc:protoc-gen-grpc-java:$&#123;grpcVersion&#125;" &#125; javapgv &#123; artifact = "io.envoyproxy.protoc-gen-validate:protoc-gen-validate:$&#123;pgvVersion&#125;" &#125; &#125; generateProtoTasks &#123; all()*.plugins &#123; javapgv &#123; option "lang=java" &#125; grpc &#123;&#125; &#125; &#125;&#125; 添加客户端ValidatingClientInterceptor123456789101112@Configurationpublic class GlobalClientInterceptorConfiguration &#123; @Bean public GlobalClientInterceptorConfigurer globalInterceptorConfigurerAdapter() &#123; ValidatorIndex index = new ReflectiveValidatorIndex(); return registry -&gt; registry .addClientInterceptors(new LogGrpcInterceptor()) .addClientInterceptors(new ValidatingClientInterceptor(index)); &#125;&#125; 服务端添加ValidatingServerInterceptor12345678910@Configurationpublic class GlobalServerInterceptorConfiguration &#123; @Bean public GlobalServerInterceptorConfigurer globalInterceptorConfigurerAdapter() &#123; ValidatorIndex index = new ReflectiveValidatorIndex(); return registry -&gt; registry.addServerInterceptors(new ValidatingServerInterceptor(index)); &#125;&#125; 测试浏览器打开idea本地http://localhost:8888/playground浏览器打开docker本地http://localhost:8000/playground 123456mutation &#123; addAuthor(request: &#123; name: &quot;&quot; &#125;) &#123; id name &#125;&#125; 因为名字验证规则为长度5~10，这里name值为空，执行返回结果 1234567891011&#123; &quot;errors&quot;: [ &#123; &quot;message&quot;: &quot;INVALID_ARGUMENT: .sample.author.AddAuthorRequest.name: length must be 5 but got: 0 - Got \&quot;\&quot;&quot; &#125; ], &quot;extensions&quot;: &#123;&#125;, &quot;data&quot;: &#123; &quot;addAuthor&quot;: null &#125;&#125; 生效，啦啦啦！ 总结介绍graphql、gprc in java world的一些问题，一些intergration的思路，新特性参数验证。 本文代码仓库地址:https://github.com/silencecorner/graphql-grpc-exmaple/tree/0.2.0]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>graphql</tag>
        <tag>grpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx部署静态vue项目时的注意事项]]></title>
    <url>%2F2019%2F08%2F17%2Fnginx%E9%83%A8%E7%BD%B2%E9%9D%99%E6%80%81vue%E9%A1%B9%E7%9B%AE%E6%97%B6%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[问题在使用webpack或者vuecli3作为脚手架开发vue项目时，使用内置的express编写测试代码都没有问题，运维拿到build生成的dist文件之后，需要通过这样方式访问http:/xxxx.com/content-path。如何部署才能保证前端页面资源正确加载呢？ 解决root部署假设content-path=post，运维同学要rename dist文件夹为post，上级文件目录C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample 1mv dist post 配置nginx.conf应该如下 1234location / &#123; root C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample; index index.html index.htm;&#125; 成功访问到http://localhost/post/ alias部署以root部署例子为前提,那么我们的配置文件nginx.conf应该如下 1234location /post &#123; alias C:\Users\silencecorner\Project\graphql-grpc-exmaple\vue-apollo-sample\dist; index index.html index.htm;&#125; 记得执行一下.\nginx.exe -s reload,这是访问我们的http://localhost/post/ 如图访问css资源http://localhost/css/app.e2707afb.css 404啦，我们怎样去给这个连接下加个post呢？以vuecli3为例,修改vue-config.js添加publicPath指定值为post 1234567891011console.log(`当前graphql网关访问地址:$&#123;process.env.VUE_APP_GRAPHQL_HTTP&#125;`)module.exports = &#123; publicPath: &apos;post&apos;, pluginOptions: &#123; graphqlMock: false, apolloEngine: false, &#125;, devServer: &#123; port: 8081, &#125;&#125; 此时重新打包再次访问就能正常访问啦！ 总结这里有两种部署方式，运维上来讲更倾向于第二种，前端可以配置使用process.env.XXX变来获取控制台变量，运维打包时想部署到任何路径都可以啦！当然使用root方式也是能达到效果，但是可能会给运维同学造成困扰，遇到这个问题的前端同学就不要说在本地我们用devServer跑都没问题的这种话啦! have a nice day ^_^]]></content>
      <categories>
        <category>前端</category>
        <category>运维</category>
      </categories>
      <tags>
        <tag>vue</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centeros docker安装及简单应用]]></title>
    <url>%2F2019%2F08%2F16%2Fcenteros-docker%E5%AE%89%E8%A3%85%E5%8F%8A%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[docker安裝卸载12345678910sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine 安裝默认安装stable版的，安装edge或者test版本的请自行查阅官方文档 12345678#安装配置管理工具sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce 安装指定版本12yum install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpmyum install -y docker-ce-17.03.0.ce-1.el7.centos.x86_64 docker 加速配置（centos7)123456789sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://id7d29lp.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.38:5000&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 配置非root用户使用docker123#bamboo 替换成你的用户名sudo setfacl -m user:bamboo:rw /var/run/docker.sock#还有一种方式就是在加入docker的group login12docker login#你的docker hub的用户名密码 用户名为参数登录 12docker login --username=gedit registry.cn-hangzhou.aliyuncs.com# 你的ali dockerhub的密码 docker machine1docker-machine create -d generic --generic-ip-address=192.168.1.67 --generic-ssh-user=administrator host67 swarm集群配置123sudo tee /etc/sysconfig/docker &lt;&lt;-&apos;EOF&apos;OPTIONS=&apos;-g /cutome-path/docker -H tcp://0.0.0.0:2375&apos;EOF 安装swarm1docker pull swarm 生成token1docker -H 192.168.1.38:8888 ps -a 设置管理节点在节点里面管理设置 1docker swarm init --advertise-addr 192.168.1.38 加入集群123docker swarm join \ --token SWMTKN-1-2hjlzufhptigxwvclhbn2b96rvn2ndl8wy8dqzn8otvjcibydp-7hppr5l9agyyp41wght5gpeo6 \ 192.168.1.41:2377 查看集群节点1docker node ls 执行命令1docker service create --name guoi-micro-shopie-shop -p 9039:9002 -p 8940:8902 --env JAVA_OPTS=&quot;-Xmx512m&quot; guoi/guoi-micro-shopie-shop --constraint &apos;node.hostname==istio-master&apos; 配置本地仓库原文链接 1docker run -d -p 5000:5000 -v /home/docker_registry:/var/lib/registry --restart=always --name registry registry:latest 123456# insecure-registries设置本地仓库位置cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://7xwv2psl.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.250:5000&quot;]&#125; 查看仓库位置 12curl -XGET http://192.168.1.250:5000/v2/_catalogcurl -XGET http://192.168.1.250:5000/v2/guoi/guoi-micro-shopie-catalog/tags/list jenkins jar运行123456789101112cd github/gedit_cloud_user_test/pid=`ps -ef | grep gedit-cloud-user-0.0.1-SNAPSHOT.jar | grep -v grep | awk &apos;&#123;print $2&#125;&apos;`if [ -n &quot;$pid&quot; ]then#!kill -9 强制终止 echo &quot;kill -9 的pid:&quot; $pid kill -9 $pidfilsgradle build -x test -x dockerBUILD_ID=DONTKILLME #jenkins环境变量nohup java -Dspring.profiles.active=test -jar -Xmx500m build/libs/gedit-cloud-user-0.0.1-SNAPSHOT.jar &gt;&gt;/root/log/gedit_user/user.log 2&gt;&amp;1&amp; docker mysql12345678910111213141516171819202122232425#dump datamysql -uroot gedit_store&gt;sqlbackup/gedit_store.docker.sqlmysql -uroot gedit_user&gt;sqlbackup/gedit_user.docker.sql#close mysqlsystemctl mysqld stop#install docker mysqldocker pull mysql #run instancedocker run -itd -p 3306:3306 mysql bash#login ttycontainer=$(docker ps|grep mysql|awk &apos;&#123;print $1&#125;&apos;)docker exec -it $container bash#create databasesmysql -urootcreate database gedit_store character set utf8mb4;create database gedit_user character set utf8mb4;exit#exit ttyexit#get mysql ipmysqlIp=$(docker ps|grep mysql|awk &apos;&#123;print $1&#125;&apos;|xargs docker inspect| grep IPAddress|sed -n &apos;2p&apos;|awk &apos;&#123;print $2&#125;&apos;|sed -e &apos;s/\&quot;//g&apos;|sed -e &apos;s/\,//g&apos;)echo &quot;mysql ip:$mysqlIp&quot;#backup data,need dump mysql datamysql -uroot -h$mysqlIp gedit_store&lt;sqlbackup/gedit_store.docker.sqlmysql -uroot -h$mysqlIp gedit_user&lt;sqlbackup/gedit_user.docker.sql 删除none镜像12#delete none imagesdocker rmi -f $(docker images | grep &apos;^&lt;none&gt;&apos; | awk &apos;&#123;print $3&#125;&apos;) jenkins docker12345678910111213141516171819BUILD_ID=DONTKILLMEgradle build -x test --refresh-dependenciessed &apos;s/-Dspring.profiles.active=test/-Dspring.profiles.active=test/g&apos; DockerfilecontainerId=$(docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $1&#125;&apos;)if [ $containerId ]then echo &quot;stop container id $containerId&quot; upContainerId=$(docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|grep &apos;Up&apos;|awk &apos;&#123;print $1&#125;&apos;) if [ $upContainerId ] then docker kill $upContainerId fi docker rm -f $containerId docker rmi -f $(docker images|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $3&#125;&apos;)figradle build docker -x test -x dockerPushdocker run --name gedit_storesearch -d -p 9091:9090 -p 9985:9985 --env JAVA_OPTS=&quot;-Xmx512m&quot; conanchen/gedit-cloud-storesearchsleep 30docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;&#123;print $1&#125;&apos;|xargs docker logs elasticsearch12docker pull docker.elastic.co/elasticsearch/elasticsearch:6.1.1docker run -d -it -p 19200:9200 -p 19300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx512m&quot; docker.elastic.co/elasticsearch/elasticsearch:6.1.1]]></content>
      <categories>
        <category>docker</category>
        <category>CI/CD</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
</search>
