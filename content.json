{"pages":[{"title":"archives","text":"","link":"/archives/index.html"},{"title":"关于我","text":"联系方式 Email：hilin2333@gmail.com 微信号：idiot_wakaka 个人信息 男/1992.08.25 本科/西华师范大学/信息与计算科学 工作年限：4年 Github：http://github.com/silencecorner 公司后台主程、研发组长，拥有较强的技术能力，喜欢钻研技术 工作期望 期望职位：高级Java开发工程师 期望薪资：税前月薪20k~30k 期望城市：北京 技能清单 熟练java、java8编程，代码习惯良好。 能够熟练使用常见的设计模式 能够熟练使用持续集成工具Jenkins、docker、k8s 熟练使用mysql、redis等关系型、非关系型数据库 熟练使用spring boot、spring cloud技术栈下的相关技术 熟悉grpc、protobuf、graphql-java 熟悉go、kotlin 有一定的shell脚本能力 对service mesh架构(istio、sofamesh)有一定的认识 北斗国信智能科技有限公司（2018年3月 ~ 至今）北斗位置服务平台工作描述 系统设计，做项目技术报告，编写设计文档 编写认证、授权服务、项目基础代码 编写对外的open api文档 功能拆解，分派任务 对其他开发同学提供技术支持 设计代码规范 code review 项目介绍北斗位置服务平台是一个saas平台，主要为公司内部和第三方提供位置数据托管、基于位置数据的功能抽象，提供统一的车、人、物位置信息服务，减少重复开发成本，解决位置数据并发度高、数据处理复杂。项目设计之初就对可靠性、稳定性、可维护性、减少技术债务做一定的考量，最终采用了传统的分布式-&gt;微服务的方式。 项目技术 mycat spring boot/spring security mybatis redis mysql 北斗关爱平台工作描述 服务设计，定义grpc、graphql 编写模块设计文档 功能拆解，分派任务 对其他开发同学提供技术支持 为服务添加istio支持以及istio运维实例 code review 项目介绍该项目采用了service mesh架构体系，istio工具集将断路器、注册发现、动态路由等微服务中常见功能都已实现，开发者无从感知。网关采用的是graphql，提供灵活的接口，减少重复代码；微服务之间采用的protobuf接口定义，使用grpc作为传输载体；所有的服务在测试环境都已经容器化，更方便运维人员做持续集成。该平台主要服务对象为老人以及儿童，通过一些iot设备与平台组织建立联系，老人可通过来电订购服务或商品，子女通过关爱端app为老人下单结账，还可以建立亲情圈加强亲人之间的联系。项目主要分为几大模块：人员组织管理、电商系统、iot应用以及通用数据管理，这其中有每个模块中又分为几个单独的应用、应用之间通过grpc交互，例如：电商系统中分为产品微服务、店铺管理、订单系统。 项目技术 docker/k8s/istio atlassian tools (研发工具，持续集成) graphql-java emqtt (iot broker) kafka redis/mysql 四川企之道软件有限公司（2016年6月 ~ 2018年3月）圈知道APP工作描述 参与产品功能设计，平衡实现和功能两级分化 基础框架搭建编写项目基础代码 功能拆解，分派任务，提供技术支持 编写代码规范、code review 项目介绍该项目采用了微服务架构，包括了红包系统、朋友圈、人脉系统、任务系统、用户系统等；在该系统中红包系统作为类秒杀系统，采用预先分包策略、数据库添加乐观锁，使用redis缓存提高系统的并发度和可靠性，在红包系统中与常见商品秒杀系统不太一样的是商品秒杀可以通过边缘计算减少应用服务器的命中次数，红包因为是顺序的，所以所有流量都在应用服务器上，其中对服务器代码进行了大量优化，经过大量压测之后红包系统的上线之后稳定运行;使用nginx+keepalived实现高可用，使用的编程式tcc事务控制（比较麻烦），使用该技术方案是为了技术复杂度，相应的代码量是正常6倍左右；在设计之初项目中就不允许使用连接查询，对复杂的sql进行拆分以提高性能，为后期数据库拆分留下了条件。 项目技术 nginx + keepalived spring cloud mybatis redis mysql 宏华技术服务管理信息系统工作描述 负责项目实施工作，将用户意见反馈给leader 对新增模块进行代码编写，对部分模块进行重写 项目介绍该项目是对已有老系统进行升级改造，新增培训模块，对现有的业务流程进行改造, 对人员调度功能进行优化, 对合同规定的其他模块进行优化;其中主要是变更系统中的售后服务流程实现逻辑，从需求接收、需求任务核实到任务收款实现任务提交给个人体现人员调动的一个流程控制、任务明细、报表统计等，使系统符合客户公司实际的售后服务流程。 项目技术 SpringMvc Hibernate Oracle Extjs","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"grpc与graphql最佳实践","text":"","link":"/2019/10/24/grpc与graphql最佳实践/"},{"title":"订单设计","text":"账单/订单定义在阅读账单/订单的区别之后，我理解为账单仅此是管帐是以money为中心，记录账务往来。主要有三种来源： 服务（虚，服务） 产品（实，购买） 资源（实，租赁） 上面的是虚只是服务可能是虚拟的也可以上门的家政服务或者是理发之类的，不存在实际的交易物品，而实存在实际的交易物品的。 账单是商品为中心的，主要管理Order2Payment的过程，包含了配送的过程，所以我理解下单到支付、配送，支付和配送可能存在也可能不存在。具体情况可以举例子： 支付不存在配送存在（赠送产品或非虚拟服务） 支付存在配送不存在 （虚拟物品，比如游戏道具） 支付存在配送存在 （实际交易物品） 支付不存在配送不存在 （赠送虚拟物品） 有两个例子比较特殊，但其实也是存在的。在账单阶段获取购物项、设置公共配送地址（每个账单可以单独修改），然后在一定时间内（商品价格或者优惠等变化影响到支付金额）生成草稿订单。在生成草稿订单时计算预计服务时间、预计配送到达时间等，草稿订单跟账单一样短时间未支付失效，原因有以下几点： 价格和优惠规则变化影响支付结果 库存，正常的电商应该是先减库存 支付平台预订单未支付超时限制 账单/订单时序图账单/订单的创建","link":"/2019/09/22/订单设计/"},{"title":"centeros docker安装及简单应用","text":"docker安裝卸载12345678910sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 安裝默认安装stable版的，安装edge或者test版本的请自行查阅官方文档 12345678#安装配置管理工具sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce 安装指定版本12yum install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpmyum install -y docker-ce-17.03.0.ce-1.el7.centos.x86_64 docker 加速配置（centos7)123456789sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;{ &quot;registry-mirrors&quot;: [&quot;https://id7d29lp.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.38:5000&quot;]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker 配置非root用户使用docker123#bamboo 替换成你的用户名sudo setfacl -m user:bamboo:rw /var/run/docker.sock#还有一种方式就是在加入docker的group login12docker login#你的docker hub的用户名密码 用户名为参数登录 12docker login --username=gedit registry.cn-hangzhou.aliyuncs.com# 你的ali dockerhub的密码 docker machine1docker-machine create -d generic --generic-ip-address=192.168.1.67 --generic-ssh-user=administrator host67 swarm集群配置123sudo tee /etc/sysconfig/docker &lt;&lt;-&apos;EOF&apos;OPTIONS=&apos;-g /cutome-path/docker -H tcp://0.0.0.0:2375&apos;EOF 安装swarm1docker pull swarm 生成token1docker -H 192.168.1.38:8888 ps -a 设置管理节点在节点里面管理设置 1docker swarm init --advertise-addr 192.168.1.38 加入集群123docker swarm join \\ --token SWMTKN-1-2hjlzufhptigxwvclhbn2b96rvn2ndl8wy8dqzn8otvjcibydp-7hppr5l9agyyp41wght5gpeo6 \\ 192.168.1.41:2377 查看集群节点1docker node ls 执行命令1docker service create --name guoi-micro-shopie-shop -p 9039:9002 -p 8940:8902 --env JAVA_OPTS=&quot;-Xmx512m&quot; guoi/guoi-micro-shopie-shop --constraint &apos;node.hostname==istio-master&apos; 配置本地仓库原文链接 1docker run -d -p 5000:5000 -v /home/docker_registry:/var/lib/registry --restart=always --name registry registry:latest 123456# insecure-registries设置本地仓库位置cat /etc/docker/daemon.json { &quot;registry-mirrors&quot;: [&quot;https://7xwv2psl.mirror.aliyuncs.com&quot;], &quot;insecure-registries&quot;: [&quot;192.168.1.250:5000&quot;]} 查看仓库位置 12curl -XGET http://192.168.1.250:5000/v2/_catalogcurl -XGET http://192.168.1.250:5000/v2/guoi/guoi-micro-shopie-catalog/tags/list jenkins jar运行123456789101112cd github/gedit_cloud_user_test/pid=`ps -ef | grep gedit-cloud-user-0.0.1-SNAPSHOT.jar | grep -v grep | awk &apos;{print $2}&apos;`if [ -n &quot;$pid&quot; ]then#!kill -9 强制终止 echo &quot;kill -9 的pid:&quot; $pid kill -9 $pidfilsgradle build -x test -x dockerBUILD_ID=DONTKILLME #jenkins环境变量nohup java -Dspring.profiles.active=test -jar -Xmx500m build/libs/gedit-cloud-user-0.0.1-SNAPSHOT.jar &gt;&gt;/root/log/gedit_user/user.log 2&gt;&amp;1&amp; docker mysql12345678910111213141516171819202122232425#dump datamysql -uroot gedit_store&gt;sqlbackup/gedit_store.docker.sqlmysql -uroot gedit_user&gt;sqlbackup/gedit_user.docker.sql#close mysqlsystemctl mysqld stop#install docker mysqldocker pull mysql #run instancedocker run -itd -p 3306:3306 mysql bash#login ttycontainer=$(docker ps|grep mysql|awk &apos;{print $1}&apos;)docker exec -it $container bash#create databasesmysql -urootcreate database gedit_store character set utf8mb4;create database gedit_user character set utf8mb4;exit#exit ttyexit#get mysql ipmysqlIp=$(docker ps|grep mysql|awk &apos;{print $1}&apos;|xargs docker inspect| grep IPAddress|sed -n &apos;2p&apos;|awk &apos;{print $2}&apos;|sed -e &apos;s/\\&quot;//g&apos;|sed -e &apos;s/\\,//g&apos;)echo &quot;mysql ip:$mysqlIp&quot;#backup data,need dump mysql datamysql -uroot -h$mysqlIp gedit_store&lt;sqlbackup/gedit_store.docker.sqlmysql -uroot -h$mysqlIp gedit_user&lt;sqlbackup/gedit_user.docker.sql 删除none镜像12#delete none imagesdocker rmi -f $(docker images | grep &apos;^&lt;none&gt;&apos; | awk &apos;{print $3}&apos;) jenkins docker12345678910111213141516171819BUILD_ID=DONTKILLMEgradle build -x test --refresh-dependenciessed &apos;s/-Dspring.profiles.active=test/-Dspring.profiles.active=test/g&apos; DockerfilecontainerId=$(docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;{print $1}&apos;)if [ $containerId ]then echo &quot;stop container id $containerId&quot; upContainerId=$(docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|grep &apos;Up&apos;|awk &apos;{print $1}&apos;) if [ $upContainerId ] then docker kill $upContainerId fi docker rm -f $containerId docker rmi -f $(docker images|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;{print $3}&apos;)figradle build docker -x test -x dockerPushdocker run --name gedit_storesearch -d -p 9091:9090 -p 9985:9985 --env JAVA_OPTS=&quot;-Xmx512m&quot; conanchen/gedit-cloud-storesearchsleep 30docker ps -a|grep &apos;conanchen/gedit-cloud-storesearch&apos;|awk &apos;{print $1}&apos;|xargs docker logs elasticsearch12docker pull docker.elastic.co/elasticsearch/elasticsearch:6.1.1docker run -d -it -p 19200:9200 -p 19300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx512m&quot; docker.elastic.co/elasticsearch/elasticsearch:6.1.1","link":"/2019/08/16/centeros-docker安装及简单应用/"},{"title":"nginx部署静态vue项目时的注意事项","text":"问题在使用webpack或者vuecli3作为脚手架开发vue项目时，使用内置的express编写测试代码都没有问题，运维拿到build生成的dist文件之后，需要通过这样方式访问http:/xxxx.com/content-path。如何部署才能保证前端页面资源正确加载呢？ 解决root部署假设content-path=post，运维同学要rename dist文件夹为post，上级文件目录C:\\Users\\silencecorner\\Project\\graphql-grpc-exmaple\\vue-apollo-sample 1mv dist post 配置nginx.conf应该如下 1234location / { root C:\\Users\\silencecorner\\Project\\graphql-grpc-exmaple\\vue-apollo-sample; index index.html index.htm;} 成功访问到http://localhost/post/ alias部署以root部署例子为前提,那么我们的配置文件nginx.conf应该如下 1234location /post { alias C:\\Users\\silencecorner\\Project\\graphql-grpc-exmaple\\vue-apollo-sample\\dist; index index.html index.htm;} 记得执行一下.\\nginx.exe -s reload,这是访问我们的http://localhost/post/ 如图访问css资源http://localhost/css/app.e2707afb.css 404啦，我们怎样去给这个连接下加个post呢？以vuecli3为例,修改vue-config.js添加publicPath指定值为post 1234567891011console.log(`当前graphql网关访问地址:${process.env.VUE_APP_GRAPHQL_HTTP}`)module.exports = { publicPath: &apos;post&apos;, pluginOptions: { graphqlMock: false, apolloEngine: false, }, devServer: { port: 8081, }} 此时重新打包再次访问就能正常访问啦！ 总结这里有两种部署方式，运维上来讲更倾向于第二种，前端可以配置使用process.env.XXX变来获取控制台变量，运维打包时想部署到任何路径都可以啦！当然使用root方式也是能达到效果，但是可能会给运维同学造成困扰，遇到这个问题的前端同学就不要说在本地我们用devServer跑都没问题的这种话啦! have a nice day ^_^","link":"/2019/08/17/nginx部署静态vue项目时的注意事项/"},{"title":"graphql grpc in java world(1)","text":"前言graphql和grpc的protobuf的schema都是一个描述性文件，只是双方的具体作用有差别而已。在Java中使用schema first的graphql-java-tools无疑是graphql在java语言的最佳入门实践，那么问题就来啦！protobuf和graphql各自都有自己的类型系统，graphql因为会序列化为json，那么就要遵从java bean的规范（序列化框架要求），protobuf使用的builder构造对象，没有默认的构造方法。本文代码仓库地址:https://github.com/silencecorner/graphql-grpc-exmaple/tree/0.2.0，如果了解graphql-java-kickstart的代码的话，可以直接查看源代码！ graphql-api nodejs实现的网关 graphql-gateway-java java实现的网关 post-api-java post服务端微服务程序 protos proto源文件 schema graphql文件目录 vue-apollo-sample 基于graphql规范的vue项目 优化思路nodejs因为在去年实践过一次，没有深入思考，写起来总感觉有一点别扭！所以最开始我的想法是改用nodejs来写去掉类型检查，也写过一个在repo的graphql-api中converternodejs写起来挺简单的，但是java才是主要开发语言，所以又按照去年的那个套路实现了一次，按照converter的思路使用了protobuf-converter类库,优化了一下但是还是有一些不适。jackson序列化框架今天我就在想能不能jackson和protobuf之间做桥接一下，google搜索了果然已经有实现的类库，终于不用再写一遍java model啦！删除代码删除之前的inputs、types package，改用protobuf生成的代码，这里桥接要注入ProtobufModule，又想能不能直接使用返回ListenableFuture实例，通过查找资料可以实现。添加GraphqlToolConfiguration.java123456789101112131415@Configurationpublic class GraphqlToolConfiguration { @Bean SchemaParserOptions options(){ ObjectMapper objectMapper = Jackson2ObjectMapperBuilder.json() .modules(new ProtobufModule(), new Jdk8Module(), new KotlinModule(), new JavaTimeModule()) .build(); return SchemaParserOptions.newOptions() .genericWrappers(SchemaParserOptions.GenericWrapper .withTransformer(ListenableFuture.class,0,ListenableFuturesExtra::toCompletableFuture, type -&gt; type)) .objectMapperProvider(fieldDefinition -&gt; objectMapper ) .useDefaultGenericWrappers(true) .build(); }} 这样我们就可以使用protobuf生成的class、grpc直接返回的ListenableFuture，字段对应protobuf的JsonName， schema.graphql123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869scalar DateTime# 作者type Author{ # unique id id: ID! # 名称 name: String}# 添加作者参数input AddAuthorRequest{ # 名字 name: String!}type Post { # id id: ID # 标题 title: String # 内容 body: String # 创建时间 createdAt: DateTime # 文章作者 author: Author}# 分页返回结果type Posts { # 总数 count: Int # 当前页 page: Int # 条数 limit: Int # 结点 nodesList: [Post]}# 添加文章参数input AddPostRequest { # 标题 title: String # 内容 body: String}# 分页参数input ListPostRequest{ # 第几页 page: Int! # 获取条数 limit: Int!}type Query { listPosts(request: ListPostRequest): Posts}type Mutation { addPost(request: AddPostRequest): Post # 新增作者 addAuthor(request: AddAuthorRequest!): Author}schema { query: Query mutation: Mutation} Mutation.java12345678910111213141516@AllArgsConstructor@Componentpublic class Mutation implements GraphQLMutationResolver { private final PostClient postClient; private final AuthorClient authorClient; public ListenableFuture&lt;PostProto.Post&gt; addPost(PostProto.AddPostRequest request){ return postClient.addPost(request.toBuilder().setAuthorId(1).build()); } public ListenableFuture&lt;AuthorProto.Author&gt; addAuthor(AuthorProto.AddAuthorRequest request){ return authorClient.addAuthor(request); }} Query.java12345678@AllArgsConstructor@Componentpublic class Query implements GraphQLQueryResolver { private final PostClient postClient; public ListenableFuture&lt;PostProto.Posts&gt; listPosts(PostProto.ListPostRequest request){ return postClient.listPost(request); }} PostResolver.java1234567891011@Componentpublic class PostResolver implements GraphQLResolver&lt;PostProto.Post&gt; { @Autowired private AuthorClient authorClient; public ListenableFuture&lt;AuthorProto.Author&gt; author(PostProto.Post post){ return authorClient.getAuthor(post.getAuthorId()); }} PostsResolver.javaproto定义的是nodes字段，生成的java代码的get方法是getNodesList，此时对应的jackson的json字段就变成nodesList，我们的graphql中使用是nodes字段，按照graphql-java-tools的解析顺序 com.bd.gateway.resolvers.post.PostsResolver.nodes(sample.PostProto$Posts) com.bd.gateway.resolvers.post.PostsResolver.getNodes(sample.PostProto$Posts) com.bd.gateway.resolvers.post.PostsResolver.nodes sample.PostProto$Posts.nodes() sample.PostProto$Posts.getNodes() sample.PostProto$Posts.nodes 添加如下代码就可以解决字段不一样的问题啦！ 1234567@Componentpublic class PostsResolver implements GraphQLResolver&lt;PostProto.Posts&gt; { public List&lt;PostProto.Post&gt; nodes(PostProto.Posts posts){ return posts.getNodesList(); }} PostClient.java1234567891011121314@Servicepublic class PostClient { @GrpcClient(&quot;post-grpc-server&quot;) private PostServiceGrpc.PostServiceFutureStub postServiceFutureStub; public ListenableFuture&lt;PostProto.Post&gt; addPost(sample.PostProto.AddPostRequest request){ return postServiceFutureStub.addPost(request); } public ListenableFuture&lt;PostProto.Posts&gt; listPost(sample.PostProto.ListPostRequest request){ return postServiceFutureStub.listPosts(request); }} AuthorClient.java1234567891011121314@Servicepublic class AuthorClient { @GrpcClient(\"author-grpc-server\") private AuthorServiceGrpc.AuthorServiceFutureStub authorServiceFutureStub; public ListenableFuture&lt;AuthorProto.Author&gt; addAuthor(AuthorProto.AddAuthorRequest request){ return authorServiceFutureStub.addAuthor(request); } public ListenableFuture&lt;AuthorProto.Author&gt; getAuthor(Integer id){ return authorServiceFutureStub.getAuthor(AuthorProto.GetAuthorRequest.newBuilder().setId(id).build()); }} new featureproto3原生是不支持数据验证的，可能我们就要手写代码一个字段一个字段去做校验，项目中就会出现大量的丑陋到爆炸的代码。这里我找到一个protoc的validate plugin，目前支持 go gogo cc for c++ java 以目前情况来讲，不需要多语言调用，即使出现多语言调用的情况也可以，不影响正常调用，只是缺少验证而已，再不济也可以自己实现嘛！ 修改proto1234import &quot;validate/validate.proto&quot;;message AddAuthorRequest{ string name = 1 [(validate.rules).string = {min_len: 5, max_len: 10}];} 修改build.gradle添加必要依赖12compile \"io.envoyproxy.protoc-gen-validate:pgv-java-stub:${pgvVersion}\"compile \"io.envoyproxy.protoc-gen-validate:pgv-java-grpc:${pgvVersion}\" 修改编译配置1234567891011121314151617181920212223protobuf { // Configure the protoc executable protoc { artifact = \"com.google.protobuf:protoc:${protocVersion}\" } plugins { grpc { artifact = \"io.grpc:protoc-gen-grpc-java:${grpcVersion}\" } javapgv { artifact = \"io.envoyproxy.protoc-gen-validate:protoc-gen-validate:${pgvVersion}\" } } generateProtoTasks { all()*.plugins { javapgv { option \"lang=java\" } grpc {} } }} 添加客户端ValidatingClientInterceptor123456789101112@Configurationpublic class GlobalClientInterceptorConfiguration { @Bean public GlobalClientInterceptorConfigurer globalInterceptorConfigurerAdapter() { ValidatorIndex index = new ReflectiveValidatorIndex(); return registry -&gt; registry .addClientInterceptors(new LogGrpcInterceptor()) .addClientInterceptors(new ValidatingClientInterceptor(index)); }} 服务端添加ValidatingServerInterceptor12345678910@Configurationpublic class GlobalServerInterceptorConfiguration { @Bean public GlobalServerInterceptorConfigurer globalInterceptorConfigurerAdapter() { ValidatorIndex index = new ReflectiveValidatorIndex(); return registry -&gt; registry.addServerInterceptors(new ValidatingServerInterceptor(index)); }} 测试浏览器打开idea本地http://localhost:8888/playground浏览器打开docker本地http://localhost:8800/playground 123456mutation { addAuthor(request: { name: &quot;&quot; }) { id name }} 因为名字验证规则为长度5~10，这里name值为空，执行返回结果 1234567891011{ &quot;errors&quot;: [ { &quot;message&quot;: &quot;INVALID_ARGUMENT: .sample.author.AddAuthorRequest.name: length must be 5 but got: 0 - Got \\&quot;\\&quot;&quot; } ], &quot;extensions&quot;: {}, &quot;data&quot;: { &quot;addAuthor&quot;: null }} 生效，啦啦啦！ 总结介绍graphql、gprc in java world的一些问题，一些intergration的思路，新特性参数验证。 本文代码仓库地址:https://github.com/silencecorner/graphql-grpc-exmaple/tree/0.2.0","link":"/2019/08/18/graphql-grpc-in-java-world-1/"},{"title":"org.hibernate.LazyInitializationException","text":"问题使用reflectasm的MethodAccess调用get方法出错，报错org.hibernate.LazyInitializationException: could not initialize proxy [com.bd.post.model.Post#2] - no Session 查错过程使用的orm框架是spring data jpa，LazyInitializationException第一时间想到hibernate和spring data jpa的懒加载机制。我理解的懒加载的概念是在真正使用数据的时候才去执行sql语句(配置外键关联)，查询对外建关联对象，但是我的model配置如下： 12345678910111213141516171819202122232425262728293031323334353637/** * @author &lt;a href=&quot;mailto:hilin2333@gmail.com&quot;&gt;created by silencecorner 2019/7/10 3:28 PM&lt;/a&gt; */@NoArgsConstructor@Entity@Data@EntityListeners(AuditingEntityListener.class)@ProtoClass(PostProto.Post.class)public class Post { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @ProtoField private Integer id; @ProtoField private String title; @ProtoField private String body; @ProtoField private Integer authorId; @CreatedDate @ProtoField(nullValue = ProtobufNullValueInspectorImpl.class,converter = LocalDateTimeConverterImpl.class) private LocalDateTime createdAt; @LastModifiedDate private LocalDateTime updatedAt; public Post(String title, String body) { this.title = title; this.body = body; } public Post(String title, String body, Integer authorId) { this.title = title; this.body = body; this.authorId = authorId; }} 这里我并没有配置外键的关联对象呀！具体的错误信息里面又有no session，在orm框架里面都有session的概念对应数据库的session，在mybatis中是sqlsession,spring data jpa和hibernate中就叫session。检查代码发现使用了JpaRepository的getOne方法获取数据 1234567891011/*** Returns a reference to the entity with the given identifier. Depending on how the JPA persistence provider is* implemented this is very likely to always return an instance and throw an* {@link javax.persistence.EntityNotFoundException} on first access. Some of them will reject invalid identifiers* immediately.** @param id must not be {@literal null}.* @return a reference to the entity with the given identifier.* @see EntityManager#getReference(Class, Object) for details on when an exception is thrown.*/T getOne(ID id); 大概的意思是，只返回一个引用，信息看异常信息，what?找到调用的方法说明 123456789101112131415161718192021/** * Get an instance, whose state may be lazily fetched. * If the requested instance does not exist in the database, * the &lt;code&gt;EntityNotFoundException&lt;/code&gt; is thrown when the instance * state is first accessed. (The persistence provider runtime is * permitted to throw the &lt;code&gt;EntityNotFoundException&lt;/code&gt; when * &lt;code&gt;getReference&lt;/code&gt; is called.) * The application should not expect that the instance state will * be available upon detachment, unless it was accessed by the * application while the entity manager was open. * @param entityClass entity class * @param primaryKey primary key * @return the found entity instance * @throws IllegalArgumentException if the first argument does * not denote an entity type or the second argument is * not a valid type for that entity&apos;s primary key or * is null * @throws EntityNotFoundException if the entity state * cannot be accessed */public &lt;T&gt; T getReference(Class&lt;T&gt; entityClass, Object primaryKey); 这里终于说啦是懒加载，然后就是不希望这个对象变成游离态，除非entity manager打开。好吧！这里顺便回忆一下hibernate和jpa的对象状态，这些状态都是从martinfowler的工作单元/Unit of Work思想得来的。这些概念都是隶属于persistence coentext，翻译过来就是持久化上下文，既然隶属一个上下文那肯定是有关系的。其中 瞬时态/transient 新new的一个就是表对象，这个对象就是瞬时态 持久态/persistent 执行一下save方法，这个对象就变成持久态 游离态/detachment 这个保存过的对象修改属性之后就变成了游离态（ps:持久态修改属性都会变成游离态)。好了，上面有一句最关键的话就是unless it was accessed by the application while the entity manager was open。去找一下我们的EntityManager接口，它是实现了Session接口的。很自然的就想到了事务，持久化没有事务怎么能行（我当时写的时候还真没有加，哈哈！）。 代码源文件 123456789101112@Transactional@Overridepublic void updatePost(PostProto.UpdatePostRequest request, StreamObserver&lt;PostProto.Post&gt; responseObserver){ check(request); // field_mask 填充字段 Configuration configuration = Configuration.builder().addIgnoredFields(new FieldsIgnore().add(Post.class, &quot;authorId&quot;, &quot;createdAt&quot;)).build(); Post post = Converter.create(configuration).toDomain(Post.class, request); Post newPost = postRepository.getOne(post.getId()); CopyUtils.copyProperties(post, newPost, true); responseObserver.onNext(modelToRpc(postRepository.save(newPost))); responseObserver.onCompleted();} 那么在什么场景下去使用返回Optional的findById，什么时候使用返回懒加载对象的getOne呢？从含义上来讲，getOne表示数据一定存在，可以在udpate的时候使用，而findById 会立刻返回结果，可能存在也可能不存在。另外，getOne因为是返回的是一个引用，还没有具体执行，给一种异步的感觉，可以在响应式web程序中使用返回CompletableFuture等封装对象，当也得符合数据必须在数据库中存在这个条件。 解决懒加载需要将相应的东西保存到session，我们能控制就是加一个事务注解在方法上@Transactional声明这个方法没有执行完之前session不关闭。因为使用的spring boot，也可以加一个不推荐使用的配置： 1spring.jpa.properties.hibernate.enable_lazy_load_no_trans=true 搞定 总结jdbc的中sesion和数据库的sesion的是一个东西，sesion中保存当前会话变量事务声明！在hibernate和jpa中还有一个persistence coentext的概念：游离态、瞬时态、持久态，这些其实都是跟session密切相关的。 多看看学学还是有必要的，have a nice day ^_^!","link":"/2019/08/19/org-hibernate-LazyInitializationException/"}],"tags":[{"name":"架构设计","slug":"架构设计","link":"/tags/架构设计/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"jenkins","slug":"jenkins","link":"/tags/jenkins/"},{"name":"vue","slug":"vue","link":"/tags/vue/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"graphql","slug":"graphql","link":"/tags/graphql/"},{"name":"grpc","slug":"grpc","link":"/tags/grpc/"},{"name":"issue","slug":"issue","link":"/tags/issue/"}],"categories":[{"name":"架构设计","slug":"架构设计","link":"/categories/架构设计/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"前端","slug":"前端","link":"/categories/前端/"},{"name":"CI/CD","slug":"docker/CI-CD","link":"/categories/docker/CI-CD/"},{"name":"运维","slug":"前端/运维","link":"/categories/前端/运维/"},{"name":"java","slug":"java","link":"/categories/java/"}]}